# -- This is for setting Security Context to a Pod. For more information checkout: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
podSecurityContext:
  fsGroup: 1000
  fsGroupChangePolicy: "OnRootMismatch"

# -- This is for setting Security Context to a Container. For more information checkout: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
securityContext:
  allowPrivilegeEscalation: false
  capabilities:
    drop:
      - ALL
  readOnlyRootFilesystem: false
  runAsNonRoot: true
  privileged: false
  runAsUser: 1000
  runAsGroup: 1000

log:
  level: info
  output:
    - console
  scopes: []
    # - concurrency
    # - external-secrets
    # - license
    # - multi-main-setup
    # - pubsub
    # - redis
    # - scaling
    # - waiting-executions

  file:
    location: "logs/n8n.log"
    maxsize: 16
    maxcount: "100"


# nodes:
#   builtin:
#     enabled: false
#     modules: []
#       # - crypto
#       # - fs
#   external:
#     allowAll: false
#     reinstallMissingPackages: false
#     packages: []
#       # - "moment@2.29.4"
#       # - "lodash@4.17.21"
#   initContainer:
#     image:
#       repository: node
#       tag: "20-alpine"
#       pullPolicy: IfNotPresent
#     resources: {}

# binaryData:
#   availableModes: []
#   mode: "default"
#   localStoragePath: ""

db:
  logging:
    enabled: false
    options: error
    maxQueryExecutionTime: 0

  type: postgresdb
  # postgresdb:
  #   host: postgres.cloudnative-pg.svc.cluster.local
  #   port: 5432
  #   database: n8n
  #   ssl:
  #     enabled: false
  
  # type: sqlite
  # sqlite:
  #   # -- SQLite database file name
  #   database: "database.sqlite"
  #   # -- SQLite database pool size. Set to `0` to disable pooling.
  #   poolSize: 0
  #   # -- Runs VACUUM operation on startup to rebuild the database. Reduces file size and optimizes indexes. This is a long running blocking operation and increases start-up time.
  #   vacuum: false

externalPostgresql:
  host: postgres.cloudnative-pg.svc.cluster.local
  port: 5432
  database: n8n


# diagnostics:
  # enabled: false
  # frontendConfig: "1zPn9bgWPzlQc0p8Gj1uiK6DOTn;https://telemetry.n8n.io"
  # backendConfig: "1zPn7YoGC3ZXE9zLeTKLuQCB4F6;https://telemetry.n8n.io"
  # postHog:
    # apiKey: "phc_4URIAm1uYfJO7j8kWSe0J8lc8IqnstRLS7Jx8NcakHo"
    # apiHost: "https://ph.n8n.io"

api:
  enabled: true
  path: api
  swagger:
    enabled: true

main:
  count: 1

  persistence:
    # -- Whether to enable persistence
    enabled: false
    # -- Name of the volume to use for persistence
    volumeName: ""
    # -- Existing claim to use for persistence
    existingClaim: ""
    # -- Mount path for persistence
    mountPath: "/home/node/.n8n"
    # -- Sub path for persistence
    subPath: ""
    # -- Storage class for persistence
    storageClass: ""
    # -- Access mode for persistence
    accessMode: ReadWriteOnce
    # -- Size for persistence
    size: 8Gi
    # -- Annotations for persistence
    annotations:
      helm.sh/resource-policy: keep
    # -- Labels for persistence
    labels: {}

  # -- Additional init containers for the main pod
  initContainers: []


worker:
  # -- Use `regular` to use main node as executer, or use `queue` to have worker nodes
  mode: regular
  concurrency: 10
  count: 2
  allNodes: false
  autoscaling:
    enabled: false
    minReplicas: 2
    maxReplicas: 10
    metrics:
      - type: Resource
        resource:
          name: memory
          target:
            type: Utilization
            averageUtilization: 80
      - type: Resource
        resource:
          name: cpu
          target:
            type: Utilization
            averageUtilization: 80

    # -- The behavior of the autoscaler.
    behavior: {}
      # scaleDown:
      #   stabilizationWindowSeconds: 300
      #   policies:
      #   - type: Percent
      #     value: 100
      #     periodSeconds: 15
      # scaleUp:
      #   stabilizationWindowSeconds: 0
      #   policies:
      #   - type: Percent
      #     value: 100
      #     periodSeconds: 15
      #   - type: Pods
      #     value: 4
      #     periodSeconds: 15
      #   selectPolicy: Max

  pdb:
    enabled: true
    minAvailable: 1
    maxUnavailable: null

  waitMainNodeReady:
    enabled: false
    overwriteSchema: ""
    overwriteUrl: ""
    healthCheckPath: "/healthz"
    additionalParameters: []

  persistence:
    enabled: false
    volumeName: ""
    existingClaim: ""
    mountPath: "/home/node/.n8n"
    subPath: ""
    storageClass: ""
    accessMode: ReadWriteOnce
    size: 8Gi
    annotations:
      helm.sh/resource-policy: keep
    labels: {}

  initContainers: []

webhook:
  mode: regular
  url: ""
  count: 2
  allNodes: false
  mcp:
    enabled: true
    resources: {}

taskRunners:
  mode: internal
  taskTimeout: 60
  taskHeartbeatInterval: 30
  maxConcurrency: 5

  broker:
    address: "127.0.0.1"
    port: 5679

  external:
    mainNodeAuthToken: ""
    workerNodeAuthToken: ""
    autoShutdownTimeout: 15
    port: 5680
    nodeOptions:
      - "--max-semi-space-size=16"
      - "--max-old-space-size=300"


workflowHistory:
  enabled: true
  # -- Time (in hours) to keep workflow history versions for. To disable it, use -1 as a value
  pruneTime: 336

timezone: "Europe/Amsterdam"
defaultLocale: en
gracefulShutdownTimeout: 30

ingress:
  enabled: true
  className: "traefik-external"
  annotations:
    # Use the default-headers middleware for security headers
    traefik.ingress.kubernetes.io/router.middlewares: traefik-system-default-headers@kubernetescrd
    # Let external-dns create a DNS record
    external-dns.alpha.kubernetes.io/target: "192.168.1.200"
  hosts:
    - host: n8n.local.naguiar.dev
      paths:
        - path: /
          pathType: Prefix
  tls:
    # The certificate-tls secret is managed by cert-manager and reflector.
    # I've added the 'n8n' namespace to reflector's allowed namespaces in a separate file change.
    - secretName: certificate-tls
      hosts:
        - n8n.local.naguiar.dev

# -- Bitnami Redis configuration
redis:
  # -- Enable redis
  enabled: false
  architecture: standalone

  master:
    persistence:
      enabled: false


# -- Bitnami PostgreSQL configuration
postgresql:
  # -- Enable postgresql
  enabled: false
  architecture: standalone

  primary:
    service:
      ports:
        postgresql: 5432

    persistence:
      enabled: true
      existingClaim: ""

  auth:
    username: ""
    password: ""
    # -- The name of the PostgreSQL database. For more information: https://docs.n8n.io/hosting/configuration/supported-databases-settings/#required-permissions
    database: "n8n"



serviceMonitor:
  enabled: false
  namespace: ""
  interval: 30s
  labels:
    release: prometheus
  timeout: 10s
  targetLabels: []

  metricRelabelings: []
    # - sourceLabels: [prometheus_replica]
    #   regex: (.*)
    #   targetLabel: another_prometheus_replica
    #   action: replace
    # - regex: prometheus_replica
    #   action: labeldrop

  # -- The prefix for the metrics
  metricsPrefix: "n8n_"

  # -- Whether to include metrics
  include:
    # -- Whether to include default metrics
    defaultMetrics: true
    # -- Whether to include cache metrics
    cacheMetrics: false
    # -- Whether to include message event bus metrics
    messageEventBusMetrics: false
    # -- Whether to include workflow id label
    workflowIdLabel: false
    # -- Whether to include node type label
    nodeTypeLabel: false
    # -- Whether to include credential type label
    credentialTypeLabel: false
    # -- Whether to include api endpoints
    apiEndpoints: false
    # -- Whether to include api path label
    apiPathLabel: false
    # -- Whether to include api method label
    apiMethodLabel: false
    # -- Whether to include api status code label
    apiStatusCodeLabel: false
    # -- Whether to include queue metrics
    queueMetrics: false
